{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Understanding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import tldextract\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import nltk\n",
    "from scipy.stats import describe\n",
    "\n",
    "# Preprocessing and model selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text processing and feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Topic modeling and clustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Classification and evaluation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "rating_path = '../data/rating.csv'\n",
    "domains_location_path = '../data/domains_location.csv'\n",
    "traffic_path = '../data/traffic.csv'\n",
    "\n",
    "rating_df = pd.read_csv(rating_path)\n",
    "domains_location_df = pd.read_csv(domains_location_path)\n",
    "traffic_data_df = pd.read_csv(traffic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of each dataset\n",
    "print(\"Rating.csv:\\n\", tabulate(rating_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(\"\\nDomains Location.csv:\\n\", tabulate(domains_location_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(\"\\nTraffic Data.csv:\\n\", tabulate(traffic_data_df.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print column names and shape\n",
    "def print_info(df, df_name):\n",
    "    print(f\"{df_name} columns: {df.columns.tolist()}\")\n",
    "    print(f\"{df_name} shape: The df has {df.shape[0]} rows and {df.shape[1]} columns.\\n\")\n",
    "\n",
    "# Print information for each data set\n",
    "print_info(rating_df, 'rating_df')\n",
    "print_info(domains_location_df, 'domains_location_df')\n",
    "print_info(traffic_data_df, 'traffic_data_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract domain\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return f\"{ext.domain}.{ext.suffix}\"\n",
    "\n",
    "# Apply the function to the 'url' column\n",
    "rating_df['domain'] = rating_df['url'].apply(extract_domain)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(rating_df[['url', 'domain']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique counts of domains\n",
    "unique_rating_domains = rating_df['domain'].nunique()\n",
    "unique_location_domains = domains_location_df['SourceCommonName'].nunique()\n",
    "unique_traffic_domains = traffic_data_df['Domain'].nunique()\n",
    "\n",
    "print(f\"Unique domains in rating_df: {unique_rating_domains}\")\n",
    "print(f\"Unique domains in domains_location_df: {unique_location_domains}\")\n",
    "print(f\"Unique domains in traffic_data_df: {unique_traffic_domains}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for sentiment values\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "\n",
    "# Apply the mapping to the title_sentiment column\n",
    "rating_df['title_sentiment_score'] = rating_df['title_sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# Verify the changes\n",
    "print(rating_df[['title_sentiment', 'title_sentiment_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge rating_df with domains_location_df\n",
    "merged_df = pd.merge(rating_df, domains_location_df, left_on='domain', right_on='SourceCommonName', how='left')\n",
    "\n",
    "# Merge the resulting DataFrame with traffic_data_df\n",
    "final_df = pd.merge(merged_df, traffic_data_df, left_on='domain', right_on='Domain', how='left')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print column names and shape\n",
    "def print_info(df, df_name):\n",
    "    print(f\"{df_name} columns: {df.columns.tolist()}\")\n",
    "    print(f\"{df_name} shape: The df has {df.shape[0]} rows and {df.shape[1]} columns.\\n\")\n",
    "\n",
    "# Print information for the data set\n",
    "print_info(final_df, 'final_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for missing values\n",
    "def check_missing_values(df):\n",
    "    total_rows = len(df)\n",
    "    missing_info = df.isnull().sum()\n",
    "    for column, missing_count in missing_info.items():\n",
    "        if missing_count > 0:\n",
    "            missing_percentage = (missing_count / total_rows) * 100\n",
    "            print(f\"The {column} column has {missing_count} missing values which is {missing_percentage:.2f}% of the column.\")\n",
    "\n",
    "check_missing_values(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop source_id column\n",
    "if 'source_id' in final_df.columns:\n",
    "    final_df = final_df.drop(columns=['source_id'])\n",
    "\n",
    "# Impute missing values\n",
    "fill_values = {\n",
    "    'author': 'Unknown',\n",
    "    'description': 'No description available',\n",
    "    'url_to_image': 'No image available',\n",
    "    'category': 'Uncategorized',\n",
    "    'SourceCommonName': 'Unknown',\n",
    "    'location': 'Unknown',\n",
    "    'Country': 'Unknown'\n",
    "}\n",
    "\n",
    "final_df.fillna(value=fill_values, inplace=True)\n",
    "\n",
    "# Verify that there are no missing values\n",
    "check_missing_values(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics and data types\n",
    "print(\"\\nfinal_df summary:\")\n",
    "print(final_df.describe(include='all'))\n",
    "print(\"\\nfinal_df data types:\")\n",
    "print(final_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'published_at' to datetime if not already\n",
    "final_df['published_at'] = pd.to_datetime(final_df['published_at'], errors='coerce')\n",
    "\n",
    "# Impute missing values\n",
    "# First, forward fill and backward fill as needed\n",
    "final_df['published_at'] = final_df['published_at'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# If still missing, fill with a default date (e.g., January 1, 2000)\n",
    "final_df['published_at'] = final_df['published_at'].fillna(pd.Timestamp('2000-01-01'))\n",
    "\n",
    "# Extract minimal set of date-related features\n",
    "final_df['published_year'] = final_df['published_at'].dt.year\n",
    "final_df['published_month'] = final_df['published_at'].dt.month\n",
    "final_df['published_day'] = final_df['published_at'].dt.day\n",
    "\n",
    "# Check the first few rows to ensure imputation and feature extraction\n",
    "print(final_df[['published_at', 'published_year', 'published_month', 'published_day']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(check_missing_values(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate content length\n",
    "final_df['content_length'] = final_df['content'].str.len()\n",
    "\n",
    "# Calculate title word count\n",
    "final_df['title_word_count'] = final_df['title'].str.split().apply(len)\n",
    "\n",
    "# Convert title_sentiment to numerical scores if needed\n",
    "sentiment_mapping = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "final_df['title_sentiment_score'] = final_df['title_sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot box plots for numerical columns with enhanced visuals\n",
    "def plot_boxplots(df):\n",
    "    # Select numerical columns\n",
    "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Set the overall style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    for column in numerical_columns:\n",
    "        # Check if the column has more than one unique value and no NaN values\n",
    "        if df[column].nunique() > 1 and df[column].notna().sum() > 0:\n",
    "            plt.figure(figsize=(12, 6))  # Increase figure size for better readability\n",
    "            sns.boxplot(x=df[column], color='skyblue')  # Add a color for distinction\n",
    "            plt.title(f'Box Plot of {column}', fontsize=16)  # Add a title with larger font size\n",
    "            plt.xlabel(column, fontsize=14)  # Label the x-axis with a larger font size\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)  # Add gridlines for better readability\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Skipping {column} due to insufficient data for plotting.\")\n",
    "\n",
    "# Call the function to plot boxplots for final_df\n",
    "plot_boxplots(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify outliers using Z-score\n",
    "def find_outliers_zscore(df, threshold=3):\n",
    "    # Select numerical columns\n",
    "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    outliers_dict = {}  # Dictionary to store outliers by column\n",
    "    \n",
    "    for column in numerical_columns:\n",
    "        # Calculate Z-scores\n",
    "        z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())\n",
    "        \n",
    "        # Identify outliers\n",
    "        outliers = df[column][z_scores > threshold]\n",
    "        \n",
    "        # Store outliers in the dictionary\n",
    "        if not outliers.empty:\n",
    "            outliers_dict[column] = outliers\n",
    "    \n",
    "    return outliers_dict\n",
    "\n",
    "# Call the function to find outliers for final_df\n",
    "outliers = find_outliers_zscore(final_df)\n",
    "\n",
    "# Print the outliers found\n",
    "if outliers:\n",
    "    for column, outlier_values in outliers.items():\n",
    "        print(f\"Outliers detected in column '{column}':\")\n",
    "        print(outlier_values)\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(\"No outliers detected using the Z-score method.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot histograms and display descriptive statistics\n",
    "def plot_histograms(df):\n",
    "    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for column in numerical_columns:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(df[column], kde=True, color='blue')\n",
    "        plt.title(f'Distribution of {column}')\n",
    "        plt.show()\n",
    "\n",
    "        # Descriptive statistics\n",
    "        mean = df[column].mean()\n",
    "        median = df[column].median()\n",
    "        std_dev = df[column].std()\n",
    "        print(f\"{column} - Mean: {mean}, Median: {median}, Std Dev: {std_dev}\\n\")\n",
    "\n",
    "plot_histograms(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot bar charts for categorical data and display value counts\n",
    "#def plot_bar_charts(df):\n",
    "    #categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    #for column in categorical_columns:\n",
    "        #plt.figure(figsize=(10, 5))\n",
    "        #df[column].value_counts().plot(kind='bar', color='green')\n",
    "        #plt.title(f'Bar Chart of {column}')\n",
    "        #plt.show()\n",
    "\n",
    "        # Display value counts\n",
    "        #print(f\"Value Counts for {column}:\")\n",
    "        #print(df[column].value_counts(), \"\\n\")\n",
    "\n",
    "#plot_bar_charts(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sources with less than a threshold into 'Other'\n",
    "threshold = 500\n",
    "source_counts = final_df['source_name'].value_counts()\n",
    "grouped_sources = source_counts[source_counts >= threshold]\n",
    "grouped_sources['Other'] = source_counts[source_counts < threshold].sum()\n",
    "\n",
    "# Plot the grouped sources as a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "grouped_sources.plot(kind='bar', color='blue')\n",
    "plt.title('Article Count by Source (Grouped)')\n",
    "plt.xlabel('Source Name')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Plot the same data as a pie chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "grouped_sources.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Article Distribution by Source (Grouped)')\n",
    "plt.ylabel('')  # Hide the y-label for a cleaner pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage contribution of each source\n",
    "percentage_contribution = (source_counts / len(final_df)) * 100\n",
    "print(percentage_contribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top and Bottom 10 Websites by News Articles Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 websites with the largest count of news articles\n",
    "top_10_websites = final_df['source_name'].value_counts().head(10)\n",
    "print(\"Top 10 Websites by Article Count:\\n\", top_10_websites)\n",
    "\n",
    "# Bottom 10 websites with the smallest count of news articles\n",
    "bottom_10_websites = final_df['source_name'].value_counts().tail(10)\n",
    "print(\"\\nBottom 10 Websites by Article Count:\\n\", bottom_10_websites)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top and Bottom 10 Websites by Visitor Traffic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define estimated visitors\n",
    "def estimate_visitors(row):\n",
    "    # Extract relevant columns\n",
    "    global_rank = row['GlobalRank']\n",
    "    ref_subnets = row['RefSubNets']\n",
    "    ref_ips = row['RefIPs']\n",
    "    \n",
    "    # Handle potential division by zero or missing values\n",
    "    if global_rank <= 0:  # GlobalRank should be a positive integer\n",
    "        return None\n",
    "    if pd.isna(ref_subnets) or pd.isna(ref_ips):\n",
    "        return None\n",
    "\n",
    "    # Example scaling factor\n",
    "    scaling_factor = 10000\n",
    "    \n",
    "    # Calculate estimated visitors\n",
    "    estimated_visitors = (1 / global_rank) * (ref_subnets + ref_ips) * scaling_factor\n",
    "    return estimated_visitors\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "final_df['EstimatedVisitors'] = final_df.apply(estimate_visitors, axis=1)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(final_df[['Domain', 'GlobalRank', 'RefSubNets', 'RefIPs', 'EstimatedVisitors']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 websites by visitor traffic\n",
    "top_10_traffic_websites = final_df[['source_name', 'EstimatedVisitors']].groupby('source_name').mean().sort_values(by='EstimatedVisitors', ascending=False).head(10)\n",
    "print(\"Top 10 Websites by Visitor Traffic:\\n\", top_10_traffic_websites)\n",
    "\n",
    "# Bottom 10 websites by visitor traffic\n",
    "bottom_10_traffic_websites = final_df[['source_name', 'EstimatedVisitors']].groupby('source_name').mean().sort_values(by='EstimatedVisitors').head(10)\n",
    "print(\"\\nBottom 10 Websites by Visitor Traffic:\\n\", bottom_10_traffic_websites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Countries with the Highest Number of News Media Organizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of news media organizations (domains) by country\n",
    "country_media_count = final_df['location'].value_counts()\n",
    "top_countries_media = country_media_count.head(10)\n",
    "print(\"Countries with the Highest Number of News Media Organizations:\\n\", top_countries_media)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Countries with Many Articles Written About Them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by location to find out the number of articles related to each country\n",
    "articles_about_countries = final_df['location'].value_counts()\n",
    "print(\"Countries with Many Articles Written About Them:\\n\", articles_about_countries.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Websites Reporting About Specific Regions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique country names or codes\n",
    "unique_countries = final_df['Country'].dropna().unique()\n",
    "\n",
    "# Convert to a DataFrame for better visualization (optional)\n",
    "unique_countries_df = pd.DataFrame(unique_countries, columns=['Country'])\n",
    "\n",
    "# Display the unique country names or codes\n",
    "print(unique_countries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated regions dictionary with new countries\n",
    "regions = {\n",
    "    'North America': ['United States'],\n",
    "    'Europe': ['United Kingdom', 'Russia'],  # Including Russia here for a broader European context\n",
    "    'Asia': ['India'],\n",
    "    'Africa': ['Nigeria'],\n",
    "    'Middle East': ['Saudi Arabia', 'UAE', 'Iran', 'Israel', 'Turkey'],\n",
    "    'South America': ['Brazil', 'Argentina', 'Chile'],\n",
    "    'Oceania': ['Australia', 'New Zealand'],\n",
    "    'Other': []  # To include any additional or unspecified regions\n",
    "}\n",
    "\n",
    "# Function to categorize a website based on its location\n",
    "def categorize_region(location):\n",
    "    for region, countries in regions.items():\n",
    "        if location in countries:\n",
    "            return region\n",
    "    return 'Other'\n",
    "\n",
    "# Apply the function to categorize each entry\n",
    "final_df['region'] = final_df['Country'].apply(categorize_region)\n",
    "\n",
    "# Count of websites reporting about specific regions\n",
    "region_report_counts = final_df['region'].value_counts()\n",
    "print(\"Websites Reporting About Specific Regions:\\n\", region_report_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Websites with Highest Count of Positive, Neutral, and Negative Sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming sentiment column exists with values 'positive', 'neutral', 'negative'\n",
    "sentiment_summary = final_df.groupby('source_name')['title_sentiment'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Descriptive statistics for sentiment\n",
    "sentiment_stats = sentiment_summary.describe()\n",
    "print(\"Descriptive Statistics for Sentiments:\\n\", sentiment_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare Impact of Mean and Median Sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'source_name' and calculate sentiment counts\n",
    "sentiment_counts = final_df.groupby('source_name')['title_sentiment'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Rename columns for clarity\n",
    "sentiment_counts.columns = ['negative_count', 'neutral_count', 'positive_count']\n",
    "\n",
    "# Get the top websites for each sentiment type\n",
    "top_positive_websites = sentiment_counts[['positive_count']].nlargest(10, 'positive_count')\n",
    "top_neutral_websites = sentiment_counts[['neutral_count']].nlargest(10, 'neutral_count')\n",
    "top_negative_websites = sentiment_counts[['negative_count']].nlargest(10, 'negative_count')\n",
    "\n",
    "print(\"Top Websites by Positive Sentiment Count:\\n\", top_positive_websites)\n",
    "print(\"\\nTop Websites by Neutral Sentiment Count:\\n\", top_neutral_websites)\n",
    "print(\"\\nTop Websites by Negative Sentiment Count:\\n\", top_negative_websites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 10 domains by visitor traffic\n",
    "top_10_domains = final_df.groupby('source_name')['EstimatedVisitors'].sum().nlargest(10).index\n",
    "\n",
    "# Filter data for top 10 domains\n",
    "top_10_df = final_df[final_df['source_name'].isin(top_10_domains)]\n",
    "\n",
    "# Calculate sentiment counts for top 10 domains\n",
    "sentiment_counts_top_10 = top_10_df.groupby('source_name')['title_sentiment'].value_counts().unstack().fillna(0)\n",
    "\n",
    "# Calculate mean and median for each sentiment\n",
    "sentiment_summary = sentiment_counts_top_10.agg(['mean', 'median', 'var'])\n",
    "\n",
    "print(\"Sentiment Summary for Top 10 Domains:\\n\", sentiment_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of mean and median\n",
    "# Data for plotting\n",
    "sentiment_types = ['Negative', 'Neutral', 'Positive']\n",
    "mean_values = [455.4, 1613.7, 334.3]\n",
    "median_values = [247.5, 1046.0, 112.0]\n",
    "\n",
    "# Create a bar plot for mean and median sentiment counts\n",
    "x = range(len(sentiment_types))  # Position of bars\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x, mean_values, width=0.4, label='Mean', color='blue', align='center')\n",
    "plt.bar([p + 0.4 for p in x], median_values, width=0.4, label='Median', color='orange', align='center')\n",
    "\n",
    "plt.xlabel('Sentiment Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Comparison of Mean and Median Sentiment Counts for Top 10 Domains')\n",
    "plt.xticks([p + 0.2 for p in x], sentiment_types)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of Sentiments for Top 10 Domains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top websites for each sentiment type\n",
    "top_positive_websites = sentiment_counts[['positive_count']].nlargest(10, 'positive_count').index\n",
    "top_neutral_websites = sentiment_counts[['neutral_count']].nlargest(10, 'neutral_count').index\n",
    "top_negative_websites = sentiment_counts[['negative_count']].nlargest(10, 'negative_count').index\n",
    "\n",
    "# Combine all top domains into a single list\n",
    "top_10_domains = set(top_positive_websites) | set(top_neutral_websites) | set(top_negative_websites)\n",
    "\n",
    "# Filter data for top 10 domains\n",
    "top_10_sentiments = final_df[final_df['source_name'].isin(top_10_domains)]\n",
    "\n",
    "# Ensure that 'title_sentiment' is used correctly (assuming it's categorical)\n",
    "if 'title_sentiment' not in top_10_sentiments.columns:\n",
    "    raise ValueError(\"Column 'title_sentiment' not found in the data.\")\n",
    "\n",
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.histplot(data=top_10_sentiments, x='title_sentiment', hue='source_name', multiple='stack', bins=30, palette='tab10')\n",
    "\n",
    "plt.title('Sentiment Distribution for Top 10 Domains by Sentiment Counts')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Source Name', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Metadata Across Sites**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of Raw Message Lengths Across Sites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of message lengths by site\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=final_df, x='source_name', y='content_length')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of Raw Message Lengths Across Sites')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of Title Word Counts Across Sites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of title word counts by site\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(data=final_df, x='source_name', y='title_word_count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of Title Word Counts Across Sites')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impact of Frequent Reporting and Sentiment on Global Ranking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensure 'title_sentiment_score' column exists and is not empty\n",
    "if 'title_sentiment_score' in final_df.columns and not final_df['title_sentiment_score'].empty:\n",
    "    # Drop rows with missing values in 'title_sentiment_score'\n",
    "    final_df = final_df.dropna(subset=['title_sentiment_score'])\n",
    "\n",
    "    # Check again if there's data left\n",
    "    if not final_df.empty:\n",
    "        # Normalize the 'title_sentiment_score' column\n",
    "        scaler = StandardScaler()\n",
    "        sentiment_scores = final_df[['title_sentiment_score']].values\n",
    "        final_df['standardized_sentiment_score'] = scaler.fit_transform(sentiment_scores)\n",
    "\n",
    "        # Calculate total number of articles and average standardized sentiment score for each website\n",
    "        reporting_sentiment_df = final_df.groupby('domain').agg(\n",
    "            total_articles=('article_id', 'count'),\n",
    "            average_sentiment=('standardized_sentiment_score', 'mean')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Perform correlation analysis\n",
    "        correlation = reporting_sentiment_df['total_articles'].corr(reporting_sentiment_df['average_sentiment'])\n",
    "        print(f\"Correlation between total articles and average standardized sentiment score: {correlation:.2f}\")\n",
    "\n",
    "        # Visualize the relationship using a scatter plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x='total_articles', y='average_sentiment', data=reporting_sentiment_df)\n",
    "        plt.title('Impact of Reporting Frequency on Standardized Sentiment Score')\n",
    "        plt.xlabel('Total Number of Articles')\n",
    "        plt.ylabel('Average Standardized Sentiment Score')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No data available after dropping missing values.\")\n",
    "else:\n",
    "    print(\"Column 'title_sentiment_score' is missing or contains no data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ML OPS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df[['title', 'category']].head())  # Check the first few rows\n",
    "print(final_df.shape)  # Check the number of rows and columns\n",
    "print(final_df['title'].isnull().sum())  # Check for missing values in 'title'\n",
    "print(final_df['category'].isnull().sum())  # Check for missing values in 'category'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since 'category' is the target variable for classification\n",
    "X = final_df['title']\n",
    "y = final_df['category']\n",
    "\n",
    "# Split the data for classification tasks (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key word Extraction Using TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df['title'].head(10))  # Display the first 10 titles to inspect their content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a few titles directly\n",
    "titles = [\n",
    "    \"superstar chef yannick alléno brings refined french cuisine to dubai\",\n",
    "    \"nice claim top spot in ligue 1 with late win against lyon\",\n",
    "    \"amphibians are the world’s most vulnerable species\"\n",
    "]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10)\n",
    "try:\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(titles)\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    print(\"TF-IDF Features:\", feature_names)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract keywords using TF-IDF with error handling\n",
    "def extract_keywords_safe(text):\n",
    "    if len(text.strip()) > 1:  # Ensure there's more than just whitespace\n",
    "        try:\n",
    "            return extract_keywords_tfidf([text])\n",
    "        except ValueError as e:\n",
    "            # Handle case where TF-IDF fails due to empty vocabulary\n",
    "            print(f\"Warning: {e} for text: {text}\")\n",
    "            return []\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "final_df['title_keywords'] = final_df['title'].apply(extract_keywords_safe)\n",
    "final_df['content_keywords'] = final_df['content'].apply(extract_keywords_safe)\n",
    "\n",
    "# Display the results\n",
    "print(final_df[['title', 'title_keywords', 'content_keywords']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare Keywords Between Title and Content**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compare key words\n",
    "def calculate_similarity(keywords1, keywords2):\n",
    "    return len(set(keywords1) & set(keywords2)) / len(set(keywords1) | set(keywords2))\n",
    "\n",
    "# Calculate similarity between title and content keywords\n",
    "final_df['title_content_similarity'] = final_df.apply(\n",
    "    lambda row: calculate_similarity(row['title_keywords'], row['content_keywords']), axis=1\n",
    ")\n",
    "\n",
    "# Display the similarity scores\n",
    "sample_similarity = final_df[['source_name', 'title_content_similarity']].head()\n",
    "print(tabulate(sample_similarity, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Summary statistics for title-content similarity\n",
    "similarity_stats = final_df['title_content_similarity'].describe()\n",
    "print(\"Summary Statistics for Title-Content Similarity:\")\n",
    "print(tabulate(similarity_stats.to_frame().T, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Additional statistics using scipy describe\n",
    "similarity_scipy_stats = describe(final_df['title_content_similarity'])\n",
    "print(\"\\nScipy Summary Statistics:\")\n",
    "print(f\"Mean: {similarity_scipy_stats.mean}\")\n",
    "print(f\"Variance: {similarity_scipy_stats.variance}\")\n",
    "print(f\"Skewness: {similarity_scipy_stats.skewness}\")\n",
    "print(f\"Kurtosis: {similarity_scipy_stats.kurtosis}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic Modeling Using Latent Dirichlet Allocation (LDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LDA\n",
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "count_data = count_vectorizer.fit_transform(final_df['content'])\n",
    "\n",
    "# Perform LDA\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda.fit(count_data)\n",
    "\n",
    "# Assign the dominant topic to each article\n",
    "final_df['dominant_topic'] = lda.transform(count_data).argmax(axis=1)\n",
    "\n",
    "# Display some sample topics\n",
    "sample_topics = final_df[['source_name', 'dominant_topic', 'title']].head()\n",
    "print(tabulate(sample_topics, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify Headlines into Predefined Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'title' and other required columns are present\n",
    "required_columns = ['title', 'content']\n",
    "missing_columns = [col for col in required_columns if col not in final_df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"Missing columns: {', '.join(missing_columns)}\")\n",
    "\n",
    "# Display the first few rows to verify data\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data, and transform the test data\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trend Analysis and Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by date and topic\n",
    "topic_trend = final_df.groupby([final_df['published_at'].dt.date, 'dominant_topic']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plotting trends\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = topic_trend.plot(kind='line', stacked=True, cmap='tab20', ax=plt.gca())\n",
    "plt.title('Topic Trends Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Topic Count')\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Topics')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust layout to fit labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Event Modeling and Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering articles by their TF-IDF features\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "final_df['event_cluster'] = kmeans.fit_predict(count_data)\n",
    "\n",
    "# Display some clustered events\n",
    "sample_clusters = final_df[['source_name', 'event_cluster', 'title']].head()\n",
    "print(tabulate(sample_clusters, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Between News Sites Reporting Events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_site_correlation = final_df.pivot_table(index='source_name', columns='event_cluster', aggfunc='size', fill_value=0)\n",
    "correlation_matrix = event_site_correlation.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "final_df['processed_text'] = final_df['content'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectirize text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(final_df['processed_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster News Articles\n",
    "num_clusters = 15  \n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "final_df['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Evaluate the clustering\n",
    "silhouette_avg = silhouette_score(X, final_df['cluster'])\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of events covered\n",
    "num_events = final_df['cluster'].nunique()\n",
    "print(f'Number of events: {num_events}')\n",
    "\n",
    "# News sites reporting events the earliest\n",
    "final_df['published_at'] = pd.to_datetime(final_df['published_at'])\n",
    "earliest_reports = final_df.groupby('source_name')['published_at'].min().reset_index()\n",
    "print(earliest_reports)\n",
    "\n",
    "# Events with the highest reporting\n",
    "event_counts = final_df['cluster'].value_counts().reset_index()\n",
    "event_counts.columns = ['cluster', 'count']\n",
    "print(event_counts)\n",
    "\n",
    "# Correlation between news sites reporting events\n",
    "correlation_matrix = final_df.pivot_table(index='published_at', columns='source_name', values='cluster', aggfunc='count').corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Versioning ML Models with MLFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('News Article Clustering')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.sklearn.log_model(kmeans, 'kmeans_model')\n",
    "    mlflow.log_metric('silhouette_score', silhouette_avg)\n",
    "    mlflow.log_param('num_clusters', num_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a more representative example input for the Naive Bayes model\n",
    "example_text = [\n",
    "    \"Breaking news: Major political shift in the United Kingdom.\",\n",
    "    \"Tech companies report quarterly earnings exceeding expectations.\",\n",
    "    \"Health experts discuss the impact of new diet trends on overall well-being.\"\n",
    "]\n",
    "example_input = vectorizer.transform(example_text)\n",
    "\n",
    "# Get the model signature from example input\n",
    "signature = infer_signature(example_input, classifier.predict(example_input))\n",
    "\n",
    "# Start MLFlow run\n",
    "with mlflow.start_run():\n",
    "    # Log the model with signature\n",
    "    mlflow.sklearn.log_model(\n",
    "        classifier,\n",
    "        \"naive_bayes_classifier\",\n",
    "        signature=signature\n",
    "    )\n",
    "    # Log parameters and metrics\n",
    "    mlflow.log_param(\"model\", \"Naive Bayes\")\n",
    "    mlflow.log_param(\"accuracy\", accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
